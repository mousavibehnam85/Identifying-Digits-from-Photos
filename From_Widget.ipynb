{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1f2172a-c8f4-4a57-b229-ef82baf39ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25 19:29:27.797642: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 21s 13ms/step - loss: 0.1676 - accuracy: 0.9472 - val_loss: 0.0564 - val_accuracy: 0.9831\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.0514 - accuracy: 0.9843 - val_loss: 0.0398 - val_accuracy: 0.9868\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 22s 15ms/step - loss: 0.0371 - accuracy: 0.9885 - val_loss: 0.0409 - val_accuracy: 0.9889\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 22s 15ms/step - loss: 0.0278 - accuracy: 0.9911 - val_loss: 0.0435 - val_accuracy: 0.9876\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 22s 15ms/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.0405 - val_accuracy: 0.9897\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 22s 15ms/step - loss: 0.0181 - accuracy: 0.9943 - val_loss: 0.0413 - val_accuracy: 0.9885\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 22s 15ms/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.0388 - val_accuracy: 0.9903\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 22s 15ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.0454 - val_accuracy: 0.9888\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 22s 15ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.0566 - val_accuracy: 0.9861\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 22s 15ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.0437 - val_accuracy: 0.9894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x169f75d30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QPushButton, QVBoxLayout, QLabel, QFileDialog\n",
    "from PyQt5.QtGui import QImage, QPixmap\n",
    "from PyQt5.QtCore import Qt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "\n",
    "# Load MNIST data\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Preprocess MNIST data\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255.0\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255.0\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model definition\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10, validation_data=(val_images, val_labels), batch_size = 32)\n",
    "\n",
    "# Save the model\n",
    "# model.save('/Users/behnam/python-projects/Neural Network/Computer Vision/Image Classification/Model_Fitting')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "245b01fc-1d05-4392-a07a-983d4026d8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3558: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Image Uploader Widget for inference\n",
    "class ImageUploader(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = tf.keras.models.load_model('/Users/behnam/python-projects/Neural Network/Computer Vision/Image Classification/Model_Fitting')\n",
    "\n",
    "        # GUI elements\n",
    "        self.upload_button = QPushButton(\"Upload Image\", clicked=self.upload_image)\n",
    "        self.img_label = QLabel()\n",
    "        self.result_label = QLabel(\"Prediction: \")\n",
    "        \n",
    "        # Layout setup\n",
    "        layout = QVBoxLayout()\n",
    "        layout.addWidget(self.upload_button)\n",
    "        layout.addWidget(self.img_label)\n",
    "        layout.addWidget(self.result_label)\n",
    "        self.setLayout(layout)\n",
    "\n",
    "    def preprocess_image(self, file_path):\n",
    "        # Image loading and preprocessing to match MNIST data\n",
    "        img = Image.open(file_path).convert('L')  # Convert to grayscale\n",
    "        img_resized = img.resize((28, 28))  # Resize to match MNIST\n",
    "        img_array = np.array(img_resized).astype('float32') / 255.0  # Normalize\n",
    "        img_array = img_array.reshape((1, 28, 28, 1))  # Reshape for the model\n",
    "        return img_array\n",
    "\n",
    "    def predict_image(self, img_array):\n",
    "        prediction = self.model.predict(img_array)\n",
    "        return np.argmax(prediction)\n",
    "\n",
    "    def upload_image(self):\n",
    "        # Image upload and display\n",
    "        options = QFileDialog.Options()\n",
    "        file_path, _ = QFileDialog.getOpenFileName(self, \"Upload Image\", \"\", \"Images (*.png *.jpg *.bmp *.gif)\", options=options)\n",
    "        if file_path:\n",
    "            img_array = self.preprocess_image(file_path)\n",
    "            class_name = self.predict_image(img_array)\n",
    "            self.result_label.setText(f\"Prediction: {class_name}\")\n",
    "            pixmap = QPixmap(file_path).scaled(100, 100, Qt.KeepAspectRatio)\n",
    "            self.img_label.setPixmap(pixmap)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "    window = ImageUploader()\n",
    "    window.setWindowTitle(\"MNIST Handwriting Prediction\")\n",
    "    window.show()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdb424b-6ac4-4dc9-87c3-be3134d6cf04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
